# Watermarking LLMs
A project that reproduces the results of the paper "A Watermark for Large Language Models" by J Kirchebauer et al.

**Overview:**
The goal of this paper is to develop a watermarking algorithm for proprietary LLMs and to dis-
tinguish human text from machine generated text. This watermark can be easily detectable
through algorithms but untraceable by humans. The algorithm used for generation and detec-
tion must be cheap so that you need not train the LLM again from scratch. The authors have
also ensured that the watermark is not heavily impacting the quality of the generated text. The
approach is to separate the logits of the next token being predicted into green and red lists at
random and use the most of the green tokens to make the sequence. The paper proposes 2 main
types of algorithms for watermarking. The first one is a hard watermark which ignores the red
list entirely and picks the next token from the green list. This raised some problems with the
quality of the text and it was problematic to properly evaluate certain low entropy sequences,
since low entropy sequences are usually the same even if generated by a machine. To overcome
this a soft watermarking technique is introduced in which the low entropy sequences are not
disturbed. Two new parameters delta and gamma are introduced in this algorithm that are used
to add to green list logits and define the ratio of the green vs red list w.r.t the vocabulary size
respectively. This tends to increase the watermark strength along with the quality of the text.
Additionally the paper also discusses a technique to make the watermarking algorithm private
along with different attacks the algorithm can be prone to in detail.

**Reproducibility analysis:**
I was able to reproduce a part of the experiments section provided in the paper. I generated the
watermarked sequences of the random prompts taken from the C4 dataset with different delta
and gamma pairs, with OPT-1.3B model for generations and OPT-2.7B model for calculating per-
plexity. In the paper the authors have generated 500 such sequences for each delta and gamma
pair. But since it takes a lot of time to generate so many sequences I have generated 25 sequences
each for 25 delta-gamma pairs. All these generations were done with multinomial sampling, in
addition to that I generated 12 files that use beam search for picking the next token. All the
details of the implementation is provided in the colab notebooks in the same folder.
Analysis compared to the paper:
    •The scatter plot of perplexity(x-axis) vs z score(y-axis) of the watermarked sequences for
    different delta and gamma pairs.
    •The scatter plot of perplexity(x-axis) vs z score(y-axis) of the watermarked sequences for
    different delta and number of beam pairs, with gamma=0.25.
    •Plot of watermark strength(y-axis) vs token length(x-axis) for delta=5.0 with multinomial
    sampling.
    •Plot of watermark strength(y-axis) vs token length(x-axis) for gamma=0.25 with multino-
    mial sampling.
    •Plot of watermark strength(y-axis) vs token length(x-axis) for gamma=0.25 with beam search
    and n beams=1.
    •False Negative rate and True positive rate for the watermark prediction with z score thresh-
    old as 4.0.

**Resources Utilization:**
The WatermarkLogitsProcesor and the WatermarkDetector are two functions provided by the
authors in their github repository taken from the extended watermark processor.py file. All my
generations use the soft watermarking algorithm. The code provided by the authors also includes
an experiments directory which has the pipeline for generating the sequences for given parame-
ters in run warmarking.py file. Only required parts of the pipeline have been taken out and used
for my reproduction part. More details about the pipeline can be seen in the colab notebooks
provided in the drive link. The authors used the C4 dataset for generation and experimentation.
I have done the same. For calculating perplexity I imported an external module called evaluate
and used it instead of the detailed implementation provided by the authors in their code. The
distinction from the authors’ experimentation vs mine is that their implementation uses an older
version of the watermarking algorithm and mine uses the latest version provided by them which
also includes a lot of changes in naming conventions.

**Application on New Datasets/Tasks:**
One of the issues with this algorithm is that it cannot handle conditional text generation. This
issue is discussed and a solution is provided in detail in the paper titled “Watermarking Condi-
tional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark
Remedy” by Yu Fu et al. It was interesting to find out how the performance of this algorithm
drops with tasks that involve text summarization or data-to-text generation. So I have taken the
XSUM dataset used in the above paper and made changes to the pipeline accordingly and gen-
erated 25 sequences with multinomial sampling having delta=10.0 and gamma=0.25. Also the
same pipeline is used to generate 25 sequences with beam search of 8 beams and same values
for delta and gamma. Since this dataset is different and the generation task is also different
from the C4 dataset, I have appended the string “Don’t Give Me the Details, Just the Summary!”
to all the documents for each row and the whole document is used as a prompt to generate the
sequence of summary with 200 token size limit. A detailed execution of this pipeline is in the
colab notebook “Watermark generation - Xsum Dataset”.

**Findings and Conclusion:**
The results show a similar pattern of perplexity vs z score both with multinomial sampling and
beam search generations(refer the analysis notebook for the reproduced graphs). However I
strongly feel that 25 sequences for each pair of parameters is a very low sample size to evalu-
ate the algorithm properly. But given the resource constraints the plots from the notebook show
that even with a slight shift in z score and perplexity the overall strength of the watermark and
its quality are close to the results presented in the paper. The same can be said about the plots
regarding the strength of the watermark vs token length. Finally one of the aims of this paper
is to reduce the false negative rate of the watermarked generations. The authors have given
the classification report for 6 pairs of delta and gamma. The analysis notebook also shows the
False negative(FPR) and True positive rates(TPR) for these pairs. It is notable that for delta=5.0
and gamma=0.5 FNR is 4%, and for delta=2.0 and gamma=0.25 the FNR is 16%. These values
are comparably more than what is presented in Table 2 of the paper. I believe these can be im-
proved with a large generation of sequences. The performance on the conditional text generation
in comparison to the earlier generated sequences is slightly worse with regards to watermark
strength and the text quality. In conclusion this is an interesting paper which introduces a novel
and cheap algorithm for watermark generation and detection for proprietary LLMs. The results
presented in the paper are reproducible and they show that with soft watermarking technique
we can maintain the quality of the text along with the strength of the watermark.